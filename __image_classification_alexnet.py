# -*- coding: utf-8 -*-
"""image_classification_alexnet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_zbbxKGcc-G_hIb-wxMLJDJ-mnP8dxJo

Alex net without leveraging pre-trained models.
"""

import tensorflow as tf
from tensorflow import keras
from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D, MaxPooling2D
from keras.models import Model
from keras.preprocessing.image import ImageDataGenerator
import keras.backend as K
import pickle
from keras.callbacks import EarlyStopping


K.set_image_data_format('channels_last')

K.set_image_data_format('channels_last')

IMAGE_SIZE = [227, 227]
batch_size = 32

train_path = 'seg_train/seg_train'
valid_path = 'seg_test/seg_test'
pred_path = 'seg_pred/seg_pred'

train_datagen = ImageDataGenerator(rescale=1./255,
                                   featurewise_center=True,
                                   featurewise_std_normalization=True,
                                   rotation_range=20,
                                   width_shift_range=0.2,
                                   height_shift_range=0.2,
                                   horizontal_flip=True,
                                   validation_split=0.2)

test_datagen = ImageDataGenerator(rescale=1./255)

training_set = train_datagen.flow_from_directory(train_path,
                                                 target_size=IMAGE_SIZE,
                                                 class_mode='categorical')

test_set = test_datagen.flow_from_directory(valid_path,
                                            target_size=IMAGE_SIZE,
                                            class_mode='categorical')

# predict_datagen = ImageDataGenerator(rescale=1. / 255)

# predict = predict_datagen.flow_from_directory(pred_path,
#                                               target_size=IMAGE_SIZE,
#                                               batch_size=1,
#                                               class_mode='categorical')


def AlexNet(input_shape):

    X_input = Input(input_shape)

    X = Conv2D(96, (11, 11), strides=4, name="conv0")(X_input)
    X = BatchNormalization(axis=3, name="bn0")(X)
    X = Activation('relu')(X)

    X = MaxPooling2D((3, 3), strides=2, name='max0')(X)

    X = Conv2D(256, (5, 5), padding='same', name='conv1')(X)
    X = BatchNormalization(axis=3, name='bn1')(X)
    X = Activation('relu')(X)

    X = MaxPooling2D((3, 3), strides=2, name='max1')(X)

    X = Conv2D(384, (3, 3), padding='same', name='conv2')(X)
    X = BatchNormalization(axis=3, name='bn2')(X)
    X = Activation('relu')(X)

    X = Conv2D(384, (3, 3), padding='same', name='conv3')(X)
    X = BatchNormalization(axis=3, name='bn3')(X)
    X = Activation('relu')(X)

    X = Conv2D(256, (3, 3), padding='same', name='conv4')(X)
    X = BatchNormalization(axis=3, name='bn4')(X)
    X = Activation('relu')(X)

    X = MaxPooling2D((3, 3), strides=2, name='max2')(X)

    X = Flatten()(X)

    X = Dense(4096, activation='relu', name="fc0")(X)

    X = Dense(4096, activation='relu', name='fc1')(X)

    X = Dense(6, activation='softmax', name='fc2')(X)

    model = Model(inputs=X_input, outputs=X, name='AlexNet')
    return model


alex = AlexNet(training_set[0][0].shape[1:])
alex.summary()

alex.compile(optimizer='adam', loss='categorical_crossentropy',
             metrics=['accuracy'])

print(training_set.class_indices)

epochs = 25
callbacks = [keras.callbacks.ModelCheckpoint("save_at_{epoch}.keras",
                                             verbose=1, save_best_only=True, save_weights_only=True, save_freq="epoch", monitor="accuracy", mode="max"),
             EarlyStopping(patience=10)]

history = alex.fit(x=training_set, validation_data=test_set,
                   epochs=epochs,  callbacks=callbacks)

# save the model to pickle file
with open('alex.pickle', 'wb') as f:
    pickle.dump(alex, f)

alex.save('alexnet')

preds = alex.evaluate(test_set)
print("Loss = " + str(preds[0]))
print("Test Accuracy = " + str(preds[1]*100))
print('Training Accuracy = ' + str(max(history.history['accuracy'])*100) + '%')

"""Save the output weights in a file."""

wt = open('weights.csv', 'w')
bs = open('biases.csv', 'w')
for idx, i in enumerate(alex.layers):
    if (isinstance(i, Conv2D) or isinstance(i, Dense)):
        weights = i.get_weights()[0]
        biases = i.get_weights()[1]
        weights = weights.flatten()
        biases = biases.flatten()
        print(weights.shape, biases.shape)
        wt.write(','.join(map(str, weights.tolist()))+"\n")
        bs.write(','.join(map(str, biases.tolist()))+"\n")

"""Run inference on new data"""
img = tf.keras.preprocessing.image.load_img(
    "20057.jpg", target_size=IMAGE_SIZE
)
img_array = tf.keras.preprocessing.image.img_to_array(img)
img_array = tf.expand_dims(img_array, 0)
predictions = alex.predict(img_array)

label_dict = {0: "building", 1: "forest",
              2: "glacier", 3: "mountain", 4: "sea", 5: "street"}
for i in range(len(predictions[0])):
    if predictions[0][i] == max(predictions[0]):
        print(label_dict[i])
